# Gu√≠a de Perfiles de Respuesta - Gemini Chat

## Descripci√≥n General

El sistema de chat RAG incluye **4 perfiles de respuesta** predefinidos que controlan la calidad, cantidad y estilo de las respuestas generadas por Gemini.

## Perfiles Disponibles

### 1. **Concise** (Concisa)
- **Longitud:** ~400 palabras (512 tokens)
- **Temperature:** 0.3 (m√°s preciso y directo)
- **Uso recomendado:**
  - Respuestas r√°pidas a FAQs
  - Consultas simples que requieren respuestas directas
  - Cuando el usuario solo necesita informaci√≥n espec√≠fica
- **Ventajas:**
  - ‚úÖ Respuestas r√°pidas
  - ‚úÖ Menor costo
  - ‚úÖ Informaci√≥n directa al grano
- **Desventajas:**
  - ‚ö†Ô∏è Puede omitir contexto importante
  - ‚ö†Ô∏è Menos explicaciones

### 2. **Balanced** (Balanceada) - *POR DEFECTO*
- **Longitud:** ~1600 palabras (2048 tokens)
- **Temperature:** 0.7 (balance creatividad/precisi√≥n)
- **Uso recomendado:**
  - Uso general del chat
  - Preguntas que requieren contexto moderado
  - Explicaciones de documentos
- **Ventajas:**
  - ‚úÖ Balance perfecto entre detalle y brevedad
  - ‚úÖ Buen costo/beneficio
  - ‚úÖ Suficiente contexto para la mayor√≠a de casos
- **Desventajas:**
  - ‚ö†Ô∏è Puede quedarse corto para an√°lisis profundos

### 3. **Detailed** (Detallada)
- **Longitud:** ~3200 palabras (4096 tokens)
- **Temperature:** 0.8 (m√°s explicativo y contextual)
- **Uso recomendado:**
  - An√°lisis de documentos complejos
  - Tutoriales paso a paso
  - Explicaciones t√©cnicas detalladas
  - Comparaciones entre documentos
- **Ventajas:**
  - ‚úÖ Explicaciones completas
  - ‚úÖ Mayor contexto
  - ‚úÖ Ejemplos y detalles adicionales
- **Desventajas:**
  - ‚ö†Ô∏è Respuestas m√°s lentas
  - ‚ö†Ô∏è Mayor costo

### 4. **Comprehensive** (Completa)
- **Longitud:** ~6400 palabras (8192 tokens)
- **Temperature:** 0.9 (m√°xima cobertura)
- **Uso recomendado:**
  - Investigaci√≥n exhaustiva
  - Reportes completos
  - An√°lisis de m√∫ltiples documentos
  - Cuando se necesita m√°ximo detalle
- **Ventajas:**
  - ‚úÖ Respuestas extremadamente detalladas
  - ‚úÖ Cubre todos los √°ngulos posibles
  - ‚úÖ Ideal para reportes profesionales
- **Desventajas:**
  - ‚ö†Ô∏è Respuestas muy largas (puede ser abrumador)
  - ‚ö†Ô∏è Mayor tiempo de generaci√≥n
  - ‚ö†Ô∏è Mayor costo

## Par√°metros T√©cnicos

| Perfil | Temperature | Max Tokens | Top P | Top K | Costo Relativo |
|--------|-------------|------------|-------|-------|----------------|
| Concise | 0.3 | 512 | 0.8 | 20 | üí∞ |
| Balanced | 0.7 | 2048 | 0.9 | 40 | üí∞üí∞ |
| Detailed | 0.8 | 4096 | 0.95 | 60 | üí∞üí∞üí∞ |
| Comprehensive | 0.9 | 8192 | 1.0 | 80 | üí∞üí∞üí∞üí∞ |

### ¬øQu√© significan estos par√°metros?

- **Temperature (0.0 - 2.0):** Controla la creatividad
  - Bajo (0.0-0.3): Respuestas m√°s predecibles y precisas
  - Medio (0.4-0.8): Balance entre creatividad y precisi√≥n
  - Alto (0.9-2.0): Respuestas m√°s creativas y variadas

- **Max Output Tokens:** L√≠mite de tokens (palabras) en la respuesta
  - 1 token ‚âà 0.75 palabras en espa√±ol
  - M√°s tokens = respuestas m√°s largas

- **Top P (0.0 - 1.0):** Diversidad del vocabulario
  - M√°s bajo: Usa palabras m√°s comunes
  - M√°s alto: Mayor variedad de vocabulario

- **Top K:** N√∫mero de opciones consideradas por token
  - M√°s bajo: Respuestas m√°s enfocadas
  - M√°s alto: Respuestas m√°s diversas

## Uso en la Interfaz

1. Abre el chat RAG
2. Selecciona tu perfil deseado en el dropdown "Calidad de Respuesta"
3. Escribe tu pregunta
4. La respuesta se generar√° usando el perfil seleccionado

## Uso Program√°tico (API)

```typescript
// Usando perfil predefinido
const response = await fetch("/api/rag/chat", {
  method: "POST",
  headers: { "Content-Type": "application/json" },
  body: JSON.stringify({
    message: "¬øCu√°ntas horas estudi√≥ Juan?",
    storageId: "storage-123",
    profile: "detailed", // concise | balanced | detailed | comprehensive
  }),
});

// O usando par√°metros personalizados
const response = await fetch("/api/rag/chat", {
  method: "POST",
  headers: { "Content-Type": "application/json" },
  body: JSON.stringify({
    message: "¬øCu√°ntas horas estudi√≥ Juan?",
    storageId: "storage-123",
    temperature: 0.5,
    maxOutputTokens: 3000,
  }),
});
```

## Costos Estimados

Basado en los precios de Gemini 2.5 Flash:
- Input: $0.075 por 1M tokens
- Output: $0.30 por 1M tokens

| Perfil | Costo Promedio por Consulta |
|--------|----------------------------|
| Concise | ~$0.0002 |
| Balanced | ~$0.0007 |
| Detailed | ~$0.0014 |
| Comprehensive | ~$0.0028 |

*Nota: Estos son estimados. El costo real depende del tama√±o de los documentos y la complejidad de la pregunta.*

## Recomendaciones

1. **Empezar con Balanced:** Es el perfil por defecto y funciona bien para la mayor√≠a de casos

2. **Usar Concise para:**
   - Preguntas simples (s√≠/no, datos espec√≠ficos)
   - Cuando necesitas respuestas r√°pidas
   - Chats con muchas consultas (para reducir costos)

3. **Usar Detailed cuando:**
   - Necesitas entender un documento complejo
   - Requieres explicaciones paso a paso
   - Est√°s aprendiendo sobre un tema nuevo

4. **Usar Comprehensive para:**
   - Reportes finales
   - An√°lisis exhaustivos
   - Cuando el detalle es cr√≠tico

## Personalizaci√≥n Avanzada

Si necesitas par√°metros espec√≠ficos, puedes modificar los perfiles en:
`/lib/ai/gemini-service.ts` en la constante `RESPONSE_PROFILES`

```typescript
export const RESPONSE_PROFILES: Record<ResponseProfile, ResponseConfig> = {
  // Personaliza aqu√≠
  custom: {
    temperature: 0.6,
    maxOutputTokens: 1500,
    topP: 0.85,
    topK: 30,
  },
};
```
